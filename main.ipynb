{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded real small matrix.\n",
      "Loaded real large matrix.\n",
      "[prepare_data] Warning: some item ids couldn't be parsed as digits. Examples: ['A T√πng - B√°nh M√¨ B√≤ N∆∞·ªõng B∆° Cambodia - L√™ H·ªìng Phong'\n",
      " 'Buzza Pizza - Nowzone' 'B√† Hai - B√°nh X√®o & B√°nh Kh·ªçt'\n",
      " 'B√°nh Cu·ªën Ba Mi·ªÅn - Tr∆∞·ªùng Chinh'\n",
      " 'B√∫n Ri√™u & Canh B√∫n - Phan ƒê√¨nh Ph√πng' 'B√∫n Th·ªãt N∆∞·ªõng Anh Ba'\n",
      " 'Cheese Coffee - H·ªìng B√†ng' 'Ch√°o S∆∞·ªùn B√© Hi·ªÅn - S√∫p Cua & B√∫n B√≤'\n",
      " 'Ch√°o S∆∞·ªùn Ch√∫ Chen - Nguy·ªÖn Tr√£i' 'Ch√® HongKong - Ê∏ØÂºèÁ≥ñÊ∞¥ - Phan Ph√∫ Ti√™n']\n",
      "[prepare_data] Warning: some item ids couldn't be parsed as digits. Examples: ['A T√πng - B√°nh M√¨ B√≤ N∆∞·ªõng B∆° Cambodia - L√™ H·ªìng Phong'\n",
      " 'Bonchon Chicken - Aeon T√¢n Ph√∫' 'Buzza Pizza - Nowzone'\n",
      " 'B√† Hai - B√°nh X√®o & B√°nh Kh·ªçt' 'B√°nh Cu·ªën Ba Mi·ªÅn - Tr∆∞·ªùng Chinh'\n",
      " 'B√∫n N∆∞·ªõc T∆∞∆°ng Mr Nhoi - Nguy·ªÖn Th∆∞·ª£ng Hi·ªÅn'\n",
      " 'B√∫n Ri√™u & Canh B√∫n - Phan ƒê√¨nh Ph√πng' 'B√∫n Th·ªãt N∆∞·ªõng Anh Ba'\n",
      " 'Cheese Coffee - H·ªìng B√†ng' 'Ch√°o S∆∞·ªùn B√© Hi·ªÅn - S√∫p Cua & B√∫n B√≤']\n",
      "Small dataset shape: (1363, 5)\n",
      "Large dataset shape: (1218, 5)\n",
      "=== IMPROVED SMALL MATRIX (110x110) ===\n",
      "\n",
      "[DEBUG] Training user 0 non-zero ratings: 14\n",
      "Improved ALS RMSE: 0.6940 (n_obs=1363)\n",
      "[üíæ] Saved: improved_als_before.csv, improved_als_after.csv\n",
      "\n",
      "=== TOP-10 G·ª¢I √ù CHO USER 0 ===\n",
      " 1. Item  27 ‚Üí D·ª± ƒëo√°n: 10.391\n",
      " 2. Item  80 ‚Üí D·ª± ƒëo√°n: 10.370\n",
      " 3. Item  13 ‚Üí D·ª± ƒëo√°n: 10.120\n",
      " 4. Item  19 ‚Üí D·ª± ƒëo√°n: 9.865\n",
      " 5. Item  16 ‚Üí D·ª± ƒëo√°n: 9.827\n",
      " 6. Item  54 ‚Üí D·ª± ƒëo√°n: 9.717\n",
      " 7. Item  70 ‚Üí D·ª± ƒëo√°n: 9.704\n",
      " 8. Item  60 ‚Üí D·ª± ƒëo√°n: 9.572\n",
      " 9. Item  77 ‚Üí D·ª± ƒëo√°n: 9.566\n",
      "10. Item   8 ‚Üí D·ª± ƒëo√°n: 9.538\n",
      "\n",
      "[DEBUG] Training user 0 non-zero ratings: 14\n",
      "Improved SGD RMSE: 1.0002 (n_obs=1363)\n",
      "[üíæ] Saved: improved_sgd_before.csv, improved_sgd_after.csv\n",
      "\n",
      "=== TOP-10 G·ª¢I √ù CHO USER 0 ===\n",
      " 1. Item  23 ‚Üí D·ª± ƒëo√°n: 7.271\n",
      " 2. Item  80 ‚Üí D·ª± ƒëo√°n: 7.147\n",
      " 3. Item  53 ‚Üí D·ª± ƒëo√°n: 6.930\n",
      " 4. Item  55 ‚Üí D·ª± ƒëo√°n: 6.911\n",
      " 5. Item  69 ‚Üí D·ª± ƒëo√°n: 6.824\n",
      " 6. Item  73 ‚Üí D·ª± ƒëo√°n: 6.800\n",
      " 7. Item   7 ‚Üí D·ª± ƒëo√°n: 6.796\n",
      " 8. Item  34 ‚Üí D·ª± ƒëo√°n: 6.793\n",
      " 9. Item  35 ‚Üí D·ª± ƒëo√°n: 6.786\n",
      "10. Item  30 ‚Üí D·ª± ƒëo√°n: 6.768\n",
      "\n",
      "=== IMPROVED LARGE MATRIX (875x110) ===\n",
      "\n",
      "[DEBUG] Training user 0 non-zero ratings: 1\n",
      "Improved ALS RMSE: 0.2253 (n_obs=1218)\n",
      "[üíæ] Saved: improved_als_before.csv, improved_als_after.csv\n",
      "\n",
      "=== TOP-10 G·ª¢I √ù CHO USER 0 ===\n",
      " 1. Item  31 ‚Üí D·ª± ƒëo√°n: 9.439\n",
      " 2. Item  54 ‚Üí D·ª± ƒëo√°n: 9.439\n",
      " 3. Item  19 ‚Üí D·ª± ƒëo√°n: 9.139\n",
      " 4. Item  13 ‚Üí D·ª± ƒëo√°n: 8.725\n",
      " 5. Item   7 ‚Üí D·ª± ƒëo√°n: 8.639\n",
      " 6. Item  59 ‚Üí D·ª± ƒëo√°n: 8.608\n",
      " 7. Item  70 ‚Üí D·ª± ƒëo√°n: 8.359\n",
      " 8. Item   5 ‚Üí D·ª± ƒëo√°n: 8.239\n",
      " 9. Item  73 ‚Üí D·ª± ƒëo√°n: 7.913\n",
      "10. Item 105 ‚Üí D·ª± ƒëo√°n: 7.830\n",
      "\n",
      "[DEBUG] Training user 0 non-zero ratings: 1\n",
      "Improved SGD RMSE: 1.3438 (n_obs=1218)\n",
      "[üíæ] Saved: improved_sgd_before.csv, improved_sgd_after.csv\n",
      "\n",
      "=== TOP-10 G·ª¢I √ù CHO USER 0 ===\n",
      " 1. Item  19 ‚Üí D·ª± ƒëo√°n: 8.781\n",
      " 2. Item  73 ‚Üí D·ª± ƒëo√°n: 8.471\n",
      " 3. Item  64 ‚Üí D·ª± ƒëo√°n: 8.445\n",
      " 4. Item  70 ‚Üí D·ª± ƒëo√°n: 8.377\n",
      " 5. Item  59 ‚Üí D·ª± ƒëo√°n: 8.200\n",
      " 6. Item 105 ‚Üí D·ª± ƒëo√°n: 8.037\n",
      " 7. Item  33 ‚Üí D·ª± ƒëo√°n: 7.871\n",
      " 8. Item  69 ‚Üí D·ª± ƒëo√°n: 7.836\n",
      " 9. Item  91 ‚Üí D·ª± ƒëo√°n: 7.710\n",
      "10. Item  30 ‚Üí D·ª± ƒëo√°n: 7.703\n",
      "\n",
      "Summary of results:\n",
      "ALS small: rmse=0.6940, before=improved_als_before.csv, after=improved_als_after.csv\n",
      "SGD small: rmse=1.0002, before=improved_sgd_before.csv, after=improved_sgd_after.csv\n",
      "ALS large: rmse=0.2253, before=improved_als_before.csv, after=improved_als_after.csv\n",
      "SGD large: rmse=1.3438, before=improved_sgd_before.csv, after=improved_sgd_after.csv\n",
      "\n",
      "Recommendations for user 0 (picked top 5, printed ascending by score):\n",
      " 1. Item  59 -> score: 8.200219\n",
      " 2. Item  70 -> score: 8.376667\n",
      " 3. Item  64 -> score: 8.445250\n",
      " 4. Item  73 -> score: 8.470523\n",
      " 5. Item  19 -> score: 8.781200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(59, 8.200219), (70, 8.376667), (64, 8.44525), (73, 8.470523), (19, 8.7812)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "# =============================\n",
    "# üß© Generate or load matrices\n",
    "# =============================\n",
    "def generate_synthetic_matrix(shape, density=0.12, min_rating=1, max_rating=5, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    m, n = shape\n",
    "    R = np.zeros((m, n))\n",
    "    num_ratings = int(m * n * density)\n",
    "    indices = np.random.choice(m * n, num_ratings, replace=False)\n",
    "    for idx in indices:\n",
    "        i, j = divmod(idx, n)\n",
    "        R[i, j] = np.random.uniform(min_rating, max_rating)\n",
    "    return pd.DataFrame(R)\n",
    "\n",
    "small_path = 'matrix_182x182.csv'\n",
    "large_path = 'full_matrix_1393x182.csv'\n",
    "\n",
    "if os.path.exists(small_path):\n",
    "    matrix_small = pd.read_csv(small_path, index_col=0)\n",
    "    print(\"Loaded real small matrix.\")\n",
    "else:\n",
    "    matrix_small = generate_synthetic_matrix((110, 110), density=0.12)\n",
    "    print(\"Generated synthetic small matrix (110x110, density 12%).\")\n",
    "\n",
    "if os.path.exists(large_path):\n",
    "    matrix_large = pd.read_csv(large_path, index_col=0)\n",
    "    print(\"Loaded real large matrix.\")\n",
    "else:\n",
    "    matrix_large = generate_synthetic_matrix((875, 110), density=0.05)\n",
    "    print(\"Generated synthetic large matrix (875x110, density 5%).\")\n",
    "\n",
    "# =============================\n",
    "# üîß Prepare data (robust cleaning + fallback)\n",
    "# =============================\n",
    "def prepare_data(matrix):\n",
    "    \"\"\"\n",
    "    Melt matrix into (user, item, rating). Try to extract digits from user/item (e.g. 'user077')->77.\n",
    "    If some entries fail, fall back to pd.factorize() to assign integer ids to each unique label.\n",
    "    Returns DataFrame with integer 'user','item' and 'rating'.\n",
    "    \"\"\"\n",
    "    df = matrix.reset_index().rename(columns={'index': 'user'}).melt(\n",
    "        id_vars='user', var_name='item', value_name='rating'\n",
    "    )\n",
    "    df = df[df['rating'] > 0].copy()\n",
    "    # Keep originals (for debugging / mapping)\n",
    "    df['user_raw'] = df['user'].astype(str)\n",
    "    df['item_raw'] = df['item'].astype(str)\n",
    "\n",
    "    # Try to extract digits\n",
    "    df['user_digits'] = df['user_raw'].str.extract(r'(\\d+)', expand=False)\n",
    "    df['item_digits'] = df['item_raw'].str.extract(r'(\\d+)', expand=False)\n",
    "\n",
    "    # If any NaN in digits, fallback to factorize\n",
    "    if df['user_digits'].isna().any() or df['item_digits'].isna().any():\n",
    "        # Show examples of problematic labels (first 10 unique)\n",
    "        bad_users = df.loc[df['user_digits'].isna(), 'user_raw'].unique()[:10]\n",
    "        bad_items = df.loc[df['item_digits'].isna(), 'item_raw'].unique()[:10]\n",
    "        if len(bad_users) > 0:\n",
    "            print(\"[prepare_data] Warning: some user ids couldn't be parsed as digits. Examples:\", bad_users)\n",
    "        if len(bad_items) > 0:\n",
    "            print(\"[prepare_data] Warning: some item ids couldn't be parsed as digits. Examples:\", bad_items)\n",
    "\n",
    "        # Use factorize to produce contiguous integer ids for user and item\n",
    "        df['user'], user_uniques = pd.factorize(df['user_raw'])\n",
    "        df['item'], item_uniques = pd.factorize(df['item_raw'])\n",
    "        # user/item are now integers 0..N-1\n",
    "        df = df[['user', 'item', 'rating', 'user_raw', 'item_raw']]\n",
    "        return df\n",
    "\n",
    "    # Otherwise safe: use extracted digits\n",
    "    df['user'] = df['user_digits'].astype(int)\n",
    "    df['item'] = df['item_digits'].astype(int)\n",
    "    df = df[['user', 'item', 'rating', 'user_raw', 'item_raw']]\n",
    "    return df\n",
    "\n",
    "small_df = prepare_data(matrix_small)\n",
    "large_df = prepare_data(matrix_large)\n",
    "\n",
    "print(\"Small dataset shape:\", small_df.shape)\n",
    "print(\"Large dataset shape:\", large_df.shape)\n",
    "\n",
    "# =============================\n",
    "# ‚öôÔ∏è ALS with Bias\n",
    "# =============================\n",
    "def als_with_bias(R, k=20, lambda_reg=0.01, max_iter=10):\n",
    "    m, n = R.shape\n",
    "    mu = np.mean(R[R > 0]) if np.any(R > 0) else 0.0\n",
    "    b_u = np.zeros(m)\n",
    "    b_i = np.zeros(n)\n",
    "    U = np.random.normal(0, 0.1, (m, k))\n",
    "    V = np.random.normal(0, 0.1, (n, k))\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        # Update item biases\n",
    "        for j in range(n):\n",
    "            ratings_j = [R[i, j] - mu - b_u[i] - np.dot(U[i], V[j]) for i in range(m) if R[i, j] > 0]\n",
    "            b_i[j] = np.mean(ratings_j) if ratings_j else 0.0\n",
    "        # Update user biases\n",
    "        for i in range(m):\n",
    "            ratings_i = [R[i, j] - mu - b_i[j] - np.dot(U[i], V[j]) for j in range(n) if R[i, j] > 0]\n",
    "            b_u[i] = np.mean(ratings_i) if ratings_i else 0.0\n",
    "        # Update V\n",
    "        for j in range(n):\n",
    "            A = np.dot(U.T, U) + lambda_reg * np.eye(k)\n",
    "            b = np.zeros(k)\n",
    "            for i in range(m):\n",
    "                if R[i, j] > 0:\n",
    "                    pred_no_v = mu + b_u[i] + b_i[j] + np.dot(U[i], V[j])\n",
    "                    err = R[i, j] - pred_no_v\n",
    "                    b += err * U[i]\n",
    "            V[j] = np.linalg.solve(A, b)\n",
    "        # Update U\n",
    "        for i in range(m):\n",
    "            A = np.dot(V.T, V) + lambda_reg * np.eye(k)\n",
    "            b = np.zeros(k)\n",
    "            for j in range(n):\n",
    "                if R[i, j] > 0:\n",
    "                    pred_no_u = mu + b_u[i] + b_i[j] + np.dot(U[i], V[j])\n",
    "                    err = R[i, j] - pred_no_u\n",
    "                    b += err * V[j]\n",
    "            U[i] = np.linalg.solve(A, b)\n",
    "    \n",
    "    return U, V, mu, b_u, b_i\n",
    "\n",
    "# =============================\n",
    "# ‚öôÔ∏è SGD with Bias + Learning Decay\n",
    "# =============================\n",
    "def sgd_with_bias(R, k=20, eta0=0.01, lambda_reg=0.01, max_iter=100):\n",
    "    m, n = R.shape\n",
    "    mu = np.mean(R[R > 0]) if np.any(R > 0) else 0.0\n",
    "    b_u = np.zeros(m)\n",
    "    b_i = np.zeros(n)\n",
    "    U = np.random.normal(0, 0.1, (m, k))\n",
    "    V = np.random.normal(0, 0.1, (n, k))\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        eta = eta0 / np.sqrt(it + 1)\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if R[i, j] > 0:\n",
    "                    pred = mu + b_u[i] + b_i[j] + np.dot(U[i], V[j])\n",
    "                    err = R[i, j] - pred\n",
    "                    b_u[i] += eta * (err - lambda_reg * b_u[i])\n",
    "                    b_i[j] += eta * (err - lambda_reg * b_i[j])\n",
    "                    U[i] += eta * (err * V[j] - lambda_reg * U[i])\n",
    "                    V[j] += eta * (err * U[i] - lambda_reg * V[j])\n",
    "    \n",
    "    return U, V, mu, b_u, b_i\n",
    "\n",
    "# =============================\n",
    "# üßÆ Evaluation with Debug + G·ª£i √Ω + Xu·∫•t CSV (robust)\n",
    "# =============================\n",
    "def evaluate_model_bias(df, train_func, model_name=\"Model\", k=20, max_iter=100, eta0=0.01):\n",
    "    \"\"\"\n",
    "    df: DataFrame with integer 'user','item','rating' columns (prepare_data ensures this or factorizes)\n",
    "    train_func: als_with_bias or sgd_with_bias\n",
    "    \"\"\"\n",
    "    # use a copy\n",
    "    dfc = df.copy()\n",
    "    # If the columns are object, try extract digits or factorize as a safety (shouldn't be needed)\n",
    "    if dfc['user'].dtype == object:\n",
    "        dfc['user'] = pd.factorize(dfc['user'])[0]\n",
    "    if dfc['item'].dtype == object:\n",
    "        dfc['item'] = pd.factorize(dfc['item'])[0]\n",
    "\n",
    "    n_users = int(dfc['user'].max()) + 1\n",
    "    n_items = int(dfc['item'].max()) + 1\n",
    "    R_train = np.zeros((n_users, n_items), dtype=float)\n",
    "    for u, i, r in dfc[['user', 'item', 'rating']].itertuples(index=False):\n",
    "        R_train[int(u), int(i)] = float(r)\n",
    "\n",
    "    # Debug: print first user's row (optional)\n",
    "    user_example = 0\n",
    "    if user_example < R_train.shape[0]:\n",
    "        print(f\"\\n[DEBUG] Training user {user_example} non-zero ratings:\", np.count_nonzero(R_train[user_example]))\n",
    "    else:\n",
    "        print(\"\\n[DEBUG] user_example >= n_users, skipping debug print.\")\n",
    "\n",
    "    # Call appropriate train function signature\n",
    "    if train_func == als_with_bias:\n",
    "        U, V, mu, b_u, b_i = train_func(R_train, k=k, max_iter=max_iter)\n",
    "    else:\n",
    "        U, V, mu, b_u, b_i = train_func(R_train, k=k, max_iter=max_iter, eta0=eta0)\n",
    "\n",
    "    # Build full prediction matrix\n",
    "    R_pred = mu + b_u[:, np.newaxis] + b_i[np.newaxis, :] + np.dot(U, V.T)\n",
    "\n",
    "    # Compute RMSE on observed entries\n",
    "    mask = R_train > 0\n",
    "    if mask.sum() > 0:\n",
    "        rmse = sqrt(mean_squared_error(R_train[mask], R_pred[mask]))\n",
    "    else:\n",
    "        rmse = float('nan')\n",
    "    print(f\"{model_name} RMSE: {rmse:.4f} (n_obs={mask.sum()})\")\n",
    "\n",
    "    # Save before/after CSVs\n",
    "    before_fname = f\"{model_name.lower().replace(' ', '_')}_before.csv\"\n",
    "    after_fname = f\"{model_name.lower().replace(' ', '_')}_after.csv\"\n",
    "    np.savetxt(before_fname, R_train, delimiter=\",\", fmt=\"%.6f\")\n",
    "    np.savetxt(after_fname, R_pred, delimiter=\",\", fmt=\"%.6f\")\n",
    "    print(f\"[üíæ] Saved: {before_fname}, {after_fname}\")\n",
    "\n",
    "    # Recommendation for a specific user (user_id = 0)\n",
    "    user_id = 0\n",
    "    if user_id < R_train.shape[0]:\n",
    "        user_real = R_train[user_id, :]\n",
    "        user_pred = R_pred[user_id, :]\n",
    "        mask_unseen = user_real == 0\n",
    "        if mask_unseen.any():\n",
    "            recommendation_scores = user_pred[mask_unseen]\n",
    "            recommend_idx = np.argsort(-recommendation_scores)[:10]\n",
    "            recommended_items = np.arange(len(user_real))[mask_unseen][recommend_idx]\n",
    "            print(f\"\\n=== TOP-10 G·ª¢I √ù CHO USER {user_id} ===\")\n",
    "            for rank, (item, score) in enumerate(zip(recommended_items, recommendation_scores[recommend_idx]), start=1):\n",
    "                print(f\"{rank:2d}. Item {item:3d} ‚Üí D·ª± ƒëo√°n: {score:.3f}\")\n",
    "        else:\n",
    "            print(f\"[!] User {user_id} ƒë√£ ƒë√°nh gi√° t·∫•t c·∫£ item (kh√¥ng c√≥ item ch∆∞a xem).\")\n",
    "    else:\n",
    "        print(f\"[!] User {user_id} kh√¥ng t·ªìn t·∫°i trong R_train (n_users={R_train.shape[0]}).\")\n",
    "\n",
    "    return {\"rmse\": rmse, \"before_file\": before_fname, \"after_file\": after_fname}\n",
    "\n",
    "# =============================\n",
    "# üÜï Recommend from CSV (choose top-k, then sort ascending before printing)\n",
    "# =============================\n",
    "def recommend_from_csv(after_csv,\n",
    "                       before_csv=None,\n",
    "                       user_id=0,\n",
    "                       top_n=5,\n",
    "                       sort_ascending=True,\n",
    "                       item_names=None):\n",
    "    \"\"\"\n",
    "    Read after_csv (prediction matrix). If before_csv provided, use it to find unseen items (==0).\n",
    "    Pick top_n highest predicted unseen items, then sort the picked items by score ascending\n",
    "    (if sort_ascending=True) before printing.\n",
    "    Returns list of (item_id, score).\n",
    "    \"\"\"\n",
    "    after = pd.read_csv(after_csv, header=None).values\n",
    "    if before_csv is not None:\n",
    "        before = pd.read_csv(before_csv, header=None).values\n",
    "        if before.shape != after.shape:\n",
    "            raise ValueError(f\"Shape mismatch: before {before.shape} vs after {after.shape}\")\n",
    "    else:\n",
    "        before = np.zeros_like(after)\n",
    "\n",
    "    n_users, n_items = after.shape\n",
    "    if user_id < 0 or user_id >= n_users:\n",
    "        raise IndexError(f\"user_id {user_id} out of range (n_users={n_users})\")\n",
    "\n",
    "    user_real = before[user_id, :].astype(float)\n",
    "    user_pred = after[user_id, :].astype(float)\n",
    "\n",
    "    unseen_mask = (user_real == 0)\n",
    "    unseen_items = np.arange(n_items)[unseen_mask]\n",
    "    unseen_scores = user_pred[unseen_mask]\n",
    "\n",
    "    if len(unseen_items) == 0:\n",
    "        print(f\"[!] User {user_id} ƒë√£ ƒë√°nh gi√° h·∫øt item (kh√¥ng c√≥ item ch∆∞a xem).\")\n",
    "        return []\n",
    "\n",
    "    # pick top_n by highest score\n",
    "    count = min(top_n, len(unseen_items))\n",
    "    top_desc_idx = np.argsort(-unseen_scores)[:count]\n",
    "    selected_items = unseen_items[top_desc_idx]\n",
    "    selected_scores = unseen_scores[top_desc_idx]\n",
    "\n",
    "    # sort the selected pairs by score ascending (or descending if requested)\n",
    "    order = np.argsort(selected_scores) if sort_ascending else np.argsort(-selected_scores)\n",
    "    final_items = selected_items[order]\n",
    "    final_scores = selected_scores[order]\n",
    "\n",
    "    print(f\"\\nRecommendations for user {user_id} (picked top {count}, printed {'ascending' if sort_ascending else 'descending'} by score):\")\n",
    "    results = []\n",
    "    for rank, (it, sc) in enumerate(zip(final_items, final_scores), start=1):\n",
    "        name_str = \"\"\n",
    "        if item_names is not None:\n",
    "            if isinstance(item_names, dict):\n",
    "                name_str = f\" - {item_names.get(int(it), '')}\"\n",
    "            elif isinstance(item_names, (list, np.ndarray, pd.Series)):\n",
    "                if int(it) < len(item_names):\n",
    "                    name_str = f\" - {item_names[int(it)]}\"\n",
    "        print(f\"{rank:2d}. Item {int(it):3d}{name_str} -> score: {sc:.6f}\")\n",
    "        results.append((int(it), float(sc)))\n",
    "    return results\n",
    "\n",
    "# =============================\n",
    "# üöÄ Run experiments + example recommend_from_csv usage\n",
    "# =============================\n",
    "print(\"=== IMPROVED SMALL MATRIX (110x110) ===\")\n",
    "res1 = evaluate_model_bias(small_df, als_with_bias, \"Improved ALS\", k=20, max_iter=10)\n",
    "res2 = evaluate_model_bias(small_df, sgd_with_bias, \"Improved SGD\", k=20, max_iter=100, eta0=0.01)\n",
    "\n",
    "print(\"\\n=== IMPROVED LARGE MATRIX (875x110) ===\")\n",
    "res3 = evaluate_model_bias(large_df, als_with_bias, \"Improved ALS\", k=20, max_iter=10)\n",
    "res4 = evaluate_model_bias(large_df, sgd_with_bias, \"Improved SGD\", k=20, max_iter=100, eta0=0.01)\n",
    "\n",
    "print(\"\\nSummary of results:\")\n",
    "for label, r in [(\"ALS small\", res1), (\"SGD small\", res2), (\"ALS large\", res3), (\"SGD large\", res4)]:\n",
    "    print(f\"{label}: rmse={r['rmse']:.4f}, before={r['before_file']}, after={r['after_file']}\")\n",
    "\n",
    "# Example: print 5 recommendations for user 0 from the SGD result, sorted ascending before printing\n",
    "after_csv = res2['after_file']   # \"improved_sgd_after.csv\"\n",
    "before_csv = res2['before_file'] # \"improved_sgd_before.csv\"\n",
    "recommend_from_csv(after_csv, before_csv=before_csv, user_id=0, top_n=5, sort_ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'real_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === G·ª¢I √ù CHO USER C·ª§ TH·ªÇ (VD: USER 0) ===\u001b[39;00m\n\u001b[0;32m      2\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m user_real \u001b[38;5;241m=\u001b[39m real_matrix[user_id, :]\n\u001b[0;32m      5\u001b[0m user_pred \u001b[38;5;241m=\u001b[39m pred_matrix[user_id, :]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ch·ªâ ch·ªçn nh·ªØng item ch∆∞a c√≥ ƒë√°nh gi√° th·∫≠t\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'real_matrix' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
