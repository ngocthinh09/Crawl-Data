{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded real small matrix.\n",
      "Loaded real large matrix.\n",
      "Small dataset shape: (1363, 3)\n",
      "Large dataset shape: (1218, 3)\n",
      "=== IMPROVED SMALL MATRIX (110x110) ===\n",
      "Improved ALS RMSE: 1.6302 (n_test=264)\n",
      "Improved SGD RMSE: 1.6265 (n_test=264)\n",
      "\n",
      "=== IMPROVED LARGE MATRIX (875x110) ===\n",
      "Improved ALS RMSE: 2.6318 (n_test=95)\n",
      "Improved SGD RMSE: 2.6397 (n_test=95)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import os\n",
    "\n",
    "# Function to generate synthetic matrix nếu files không tồn tại\n",
    "def generate_synthetic_matrix(shape, density=0.12, min_rating=1, max_rating=5, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    m, n = shape\n",
    "    R = np.zeros((m, n))\n",
    "    num_ratings = int(m * n * density)\n",
    "    indices = np.random.choice(m * n, num_ratings, replace=False)\n",
    "    for idx in indices:\n",
    "        i, j = divmod(idx, n)\n",
    "        R[i, j] = np.random.uniform(min_rating, max_rating)\n",
    "    return pd.DataFrame(R)\n",
    "\n",
    "# Load hoặc generate ma trận for both small and large\n",
    "small_path = 'matrix_110x110.csv'\n",
    "large_path = 'full_matrix_875x110.csv'\n",
    "\n",
    "if os.path.exists(small_path):\n",
    "    matrix_small = pd.read_csv(small_path, index_col=0)\n",
    "    print(\"Loaded real small matrix.\")\n",
    "else:\n",
    "    matrix_small = generate_synthetic_matrix((110, 110), density=0.12)\n",
    "    print(\"Generated synthetic small matrix (110x110, density 12%).\")\n",
    "\n",
    "if os.path.exists(large_path):\n",
    "    matrix_large = pd.read_csv(large_path, index_col=0)\n",
    "    print(\"Loaded real large matrix.\")\n",
    "else:\n",
    "    matrix_large = generate_synthetic_matrix((875, 110), density=0.05)\n",
    "    print(\"Generated synthetic large matrix (875x110, density 5%).\")\n",
    "\n",
    "# FIXED: prepare_data function\n",
    "def prepare_data(matrix):\n",
    "    df = matrix.reset_index().rename(columns={'index': 'user'}).melt(id_vars='user', var_name='item', value_name='rating')\n",
    "    df = df[df['rating'] > 0].copy()  # Bỏ implicit 0\n",
    "    return df\n",
    "\n",
    "small_df = prepare_data(matrix_small)\n",
    "large_df = prepare_data(matrix_large)\n",
    "\n",
    "print(\"Small dataset shape:\", small_df.shape)\n",
    "print(\"Large dataset shape:\", large_df.shape)\n",
    "\n",
    "# IMPROVED ALS with Bias\n",
    "def als_with_bias(R, k=20, lambda_reg=0.01, max_iter=10):\n",
    "    m, n = R.shape\n",
    "    # Global mean\n",
    "    mu = np.mean(R[R > 0])\n",
    "    # Initialize biases\n",
    "    b_u = np.zeros(m)\n",
    "    b_i = np.zeros(n)\n",
    "    # Initialize factors\n",
    "    U = np.random.normal(0, 0.1, (m, k))\n",
    "    V = np.random.normal(0, 0.1, (n, k))\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        # Update item biases (fix others)\n",
    "        for j in range(n):\n",
    "            ratings_j = [R[i,j] - mu - b_u[i] - np.dot(U[i], V[j]) for i in range(m) if R[i,j] > 0]\n",
    "            b_i[j] = np.mean(ratings_j) if ratings_j else 0\n",
    "        # Update user biases\n",
    "        for i in range(m):\n",
    "            ratings_i = [R[i,j] - mu - b_i[j] - np.dot(U[i], V[j]) for j in range(n) if R[i,j] > 0]\n",
    "            b_u[i] = np.mean(ratings_i) if ratings_i else 0\n",
    "        # Update V (fix U, biases)\n",
    "        for j in range(n):\n",
    "            A = np.dot(U.T, U) + lambda_reg * np.eye(k)\n",
    "            b = np.zeros(k)\n",
    "            for i in range(m):\n",
    "                if R[i, j] > 0:\n",
    "                    pred_no_v = mu + b_u[i] + b_i[j] + np.dot(U[i], V[j])\n",
    "                    err = R[i, j] - pred_no_v\n",
    "                    b += err * U[i]\n",
    "            V[j] = np.linalg.solve(A, b)\n",
    "        # Update U\n",
    "        for i in range(m):\n",
    "            A = np.dot(V.T, V) + lambda_reg * np.eye(k)\n",
    "            b = np.zeros(k)\n",
    "            for j in range(n):\n",
    "                if R[i, j] > 0:\n",
    "                    pred_no_u = mu + b_u[i] + b_i[j] + np.dot(U[i], V[j])\n",
    "                    err = R[i, j] - pred_no_u\n",
    "                    b += err * V[j]\n",
    "            U[i] = np.linalg.solve(A, b)\n",
    "    \n",
    "    return U, V, mu, b_u, b_i\n",
    "\n",
    "# IMPROVED SGD with Bias and Eta Decay\n",
    "def sgd_with_bias(R, k=20, eta0=0.01, lambda_reg=0.01, max_iter=100):\n",
    "    m, n = R.shape\n",
    "    # Global mean\n",
    "    mu = np.mean(R[R > 0])\n",
    "    # Initialize biases\n",
    "    b_u = np.zeros(m)\n",
    "    b_i = np.zeros(n)\n",
    "    # Initialize factors\n",
    "    U = np.random.normal(0, 0.1, (m, k))\n",
    "    V = np.random.normal(0, 0.1, (n, k))\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        eta = eta0 / np.sqrt(it + 1)  # Eta decay\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if R[i, j] > 0:\n",
    "                    pred = mu + b_u[i] + b_i[j] + np.dot(U[i], V[j])\n",
    "                    err = R[i, j] - pred\n",
    "                    # Update biases\n",
    "                    b_u[i] += eta * (err - lambda_reg * b_u[i])\n",
    "                    b_i[j] += eta * (err - lambda_reg * b_i[j])\n",
    "                    # Update U\n",
    "                    U[i] += eta * (err * V[j] - lambda_reg * U[i])\n",
    "                    # Update V\n",
    "                    V[j] += eta * (err * U[i] - lambda_reg * V[j])\n",
    "    \n",
    "    return U, V, mu, b_u, b_i\n",
    "\n",
    "# Updated evaluate_model for bias models\n",
    "def evaluate_model_bias(df, model_func, model_name, **kwargs):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    user_to_idx = {u: idx for idx, u in enumerate(train_df['user'].unique())}\n",
    "    item_to_idx = {it: idx for idx, it in enumerate(train_df['item'].unique())}\n",
    "    \n",
    "    m_train = len(user_to_idx)\n",
    "    n_train = len(item_to_idx)\n",
    "    R_train = np.zeros((m_train, n_train))\n",
    "    for _, row in train_df.iterrows():\n",
    "        i = user_to_idx[row['user']]\n",
    "        j = item_to_idx[row['item']]\n",
    "        R_train[i, j] = row['rating']\n",
    "    \n",
    "    # Fit model\n",
    "    U, V, mu, b_u, b_i = model_func(R_train, **kwargs)\n",
    "    \n",
    "    # Predict & RMSE\n",
    "    preds, actuals = [], []\n",
    "    for _, row in test_df.iterrows():\n",
    "        if row['user'] in user_to_idx and row['item'] in item_to_idx:\n",
    "            i = user_to_idx[row['user']]\n",
    "            j = item_to_idx[row['item']]\n",
    "            pred = mu + b_u[i] + b_i[j] + np.dot(U[i], V[j])\n",
    "            actual = row['rating']\n",
    "            preds.append(max(1, min(5, pred)))\n",
    "            actuals.append(actual)\n",
    "    \n",
    "    if len(preds) == 0:\n",
    "        return f\"{model_name}: No overlapping test data\"\n",
    "    rmse = sqrt(mean_squared_error(actuals, preds))\n",
    "    return f\"{model_name} RMSE: {rmse:.4f} (n_test={len(actuals)})\"\n",
    "\n",
    "# Chạy thử với improved models on both\n",
    "print(\"=== IMPROVED SMALL MATRIX (110x110) ===\")\n",
    "print(evaluate_model_bias(small_df, als_with_bias, \"Improved ALS\", k=20, max_iter=10))\n",
    "print(evaluate_model_bias(small_df, sgd_with_bias, \"Improved SGD\", k=20, max_iter=100, eta0=0.01))\n",
    "\n",
    "print(\"\\n=== IMPROVED LARGE MATRIX (875x110) ===\")\n",
    "print(evaluate_model_bias(large_df, als_with_bias, \"Improved ALS\", k=20, max_iter=10))\n",
    "print(evaluate_model_bias(large_df, sgd_with_bias, \"Improved SGD\", k=20, max_iter=100, eta0=0.01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
